import gradio as gr
from ultralytics import YOLO
import PIL.Image as Image
import numpy as np
import cv2
import torch
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image

# è®¾å¤‡é…ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åŠ è½½YOLOæ¨¡å‹
model = YOLO("/root/autodl-tmp/ultralytics-main/runs/train/ep-original-bifpn-128/weights/best.pt").to(device)

# å¯ç”¨æ¢¯åº¦è®¡ç®—
for param in model.model.parameters():
    param.requires_grad_(True)

# Grad-CAMåŒ…è£…ç±»
class YOLOWrapper(torch.nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model.model
        self.target_layer = self.model.model[12]
        self.activations = None
        self.gradients = None
        self.target_layer.register_forward_hook(self.save_activations)
        self.target_layer.register_full_backward_hook(self.save_gradients)

    def save_activations(self, module, input, output):
        self.activations = output.detach().requires_grad_(True)

    def save_gradients(self, module, grad_input, grad_output):
        self.gradients = grad_output[0].detach()

    def forward(self, x):
        output = self.model(x)
        return output[0] if isinstance(output, tuple) else output

# åˆå§‹åŒ–Grad-CAM
target_model = YOLOWrapper(model).to(device)
cam = GradCAM(model=target_model, target_layers=[target_model.target_layer])

def preprocess_image(img):
    """å›ºå®šå°ºå¯¸é¢„å¤„ç†"""
    try:
        img = np.array(img)
        img = cv2.resize(img, (640, 640))  # å¼ºåˆ¶ç¼©æ”¾
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        img = np.float32(img) / 255.0
        return img
    except Exception as e:
        print(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {str(e)}")
        return None

def generate_heatmap(img_tensor):
    """ç”Ÿæˆå›ºå®šå°ºå¯¸çƒ­åŠ›å›¾"""
    try:
        img_tensor = img_tensor.to(device).requires_grad_(True)
        
        class FeatureMapTarget:
            def __call__(self, model_output):
                return torch.sum(model_output)
        
        grayscale_cam = cam(input_tensor=img_tensor, targets=[FeatureMapTarget()])
        grayscale_cam = grayscale_cam[0, :]
        grayscale_cam = cv2.resize(grayscale_cam, (640, 640))  # ç¡®ä¿è¾“å‡ºå°ºå¯¸
        grayscale_cam = np.maximum(grayscale_cam, 0)
        grayscale_cam = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min() + 1e-8)
        return grayscale_cam
    except Exception as e:
        print(f"çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

def predict_image(img, conf_thresh=0.25, iou_thresh=0.45):
    """å››çª—ä½“é¢„æµ‹å‡½æ•°"""
    try:
        processed_img = preprocess_image(img)
        if processed_img is None:
            raise ValueError("å›¾åƒé¢„å¤„ç†å¤±è´¥")
        
        img_tensor = torch.from_numpy(processed_img.transpose(2, 0, 1)).unsqueeze(0).float()
        
        results = model.predict(
            source=img,
            conf=conf_thresh,
            iou=iou_thresh,
            imgsz=640,
            device=device.type,
            verbose=False
        )
        
        if len(results) == 0:
            raise ValueError("æœªæ£€æµ‹åˆ°ç›®æ ‡")
        r = results[0]
        
        # ç”Ÿæˆæ£€æµ‹ç»“æœ
        det_img = Image.fromarray(r.plot()[..., ::-1]).resize((640, 640))
        original_img = img.resize((640, 640)) if img else Image.new('RGB', (640, 640), (128,128,128))
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        heatmap = generate_heatmap(img_tensor)
        if heatmap is not None:
            heatmap_img = show_cam_on_image(processed_img, heatmap, use_rgb=True)
            heatmap_img = Image.fromarray(heatmap_img).resize((640, 640))
        else:
            heatmap_img = Image.new('RGB', (640, 640), (128, 128, 128))

        # ç”Ÿæˆç‰¹å¾å¯è§†åŒ–å›¾ï¼ˆè¿™é‡Œå‡è®¾å°±æ˜¯çƒ­åŠ›å›¾ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
        feature_visualization_img = heatmap_img

        return [original_img, det_img, heatmap_img, feature_visualization_img]
    
    except Exception as e:
        print(f"é¢„æµ‹é”™è¯¯: {str(e)}")
        error_img = Image.new('RGB', (640, 640), (255, 0, 0))
        return [error_img, error_img, error_img, error_img]

def clear_outputs():
    """æ¸…ç©ºæ‰€æœ‰è¾“å‡º"""
    return [None, None, None, None]

# ç•Œé¢å¸ƒå±€
with gr.Blocks(css="""
/* ä¸»å®¹å™¨ */
.main-container {
    max-width: 100vw !important;
    padding: 20px !important;
    background: #f5f7fb !important;
}

/* å››çª—æ ¼æ°´å¹³å¸ƒå±€ */
.horizontal-panels {
    display: flex !important;
    gap: 20px !important;
    padding: 15px 0 !important;
    overflow-x: auto !important;
}

/* ç»Ÿä¸€çª—ä½“æ ·å¼ */
.panel {
    flex: 0 0 440px !important;
    height: 480px !important;
    background: white !important;
    border-radius: 12px !important;
    box-shadow: 0 4px 12px rgba(0,0,0,0.08) !important;
    padding: 15px !important;
}

/* å›¾ç‰‡å®¹å™¨ */
.image-container {
    height: 400px !important;
    border: 2px dashed #e1e4e9 !important;
    border-radius: 8px !important;
    background: #f8f9fa !important;
    margin-bottom: 10px !important;
}
.image-container img {
    object-fit: contain !important;
}

/* æ§åˆ¶é¢æ¿ */
.control-panel {
    background: white !important;
    border-radius: 12px !important;
    padding: 25px 40px !important;
    margin-top: 25px !important;
    box-shadow: 0 4px 12px rgba(0,0,0,0.06) !important;
}

/* æŒ‰é’®æ ·å¼ */
.action-btns {
    display: flex !important;
    gap: 15px !important;
    margin-top: 20px !important;
}
.btn-primary {
    background: #4CAF50 !important;
    color: white !important;
    padding: 12px 35px !important;
    border-radius: 8px !important;
    transition: all 0.3s !important;
}
.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 5px 15px rgba(76,175,80,0.3);
}
.btn-secondary {
    background: #6c757d !important;
    color: white !important;
}

/* ç»Ÿè®¡ä¿¡æ¯æ ·å¼ */
.stats-panel {
    font-family: monospace !important;
    padding: 15px !important;
    background: #f8f9fa !important;
    border-radius: 8px !important;
}
""") as demo:
    
    with gr.Column(elem_classes="main-container"):
        # æ ‡é¢˜
        gr.Markdown("# ğŸ… ç•ªèŒ„æœå®æ£€æµ‹ç³»ç»Ÿ", elem_id="header")
        
        # å››çª—æ ¼æ°´å¹³å¸ƒå±€
        with gr.Row(elem_classes="horizontal-panels"):
            # çª—ä½“1ï¼šåŸå§‹å›¾åƒ
            with gr.Column(elem_classes="panel"):
                gr.Markdown("### åŸå§‹å›¾åƒ")
                original_output = gr.Image(elem_classes="image-container")
            
            # çª—ä½“2ï¼šæ£€æµ‹ç»“æœ
            with gr.Column(elem_classes="panel"):
                gr.Markdown("### æ£€æµ‹ç»“æœ")
                det_output = gr.Image(elem_classes="image-container")
            
            # çª—ä½“3ï¼šçƒ­åŠ›å›¾
            with gr.Column(elem_classes="panel"):
                gr.Markdown("### çƒ­åŠ›å›¾åˆ†æ")
                heatmap_output = gr.Image(elem_classes="image-container")
            
            # çª—ä½“4ï¼šç‰¹å¾å¯è§†åŒ–
            with gr.Column(elem_classes="panel"):
                gr.Markdown("### ç‰¹å¾å¯è§†åŒ–")
                feature_visualization_output = gr.Image(elem_classes="image-container")

        # åº•éƒ¨æ§åˆ¶é¢æ¿
        with gr.Column(elem_classes="control-panel"):
            with gr.Row():
                # ä¸Šä¼ åŒºåŸŸ
                input_img = gr.Image(type="pil", label="ä¸Šä¼ å›¾ç‰‡", width=300)
                
                # å‚æ•°æ§åˆ¶
                with gr.Column():
                    conf_slider = gr.Slider(0, 1, 0.25, label="ç½®ä¿¡åº¦é˜ˆå€¼")
                    iou_slider = gr.Slider(0, 1, 0.45, label="äº¤å¹¶æ¯”é˜ˆå€¼")
                    
                    # æ“ä½œæŒ‰é’®
                    with gr.Row(elem_classes="action-btns"):
                        submit_btn = gr.Button("å¼€å§‹æ£€æµ‹", elem_classes="btn-primary")
                        clear_btn = gr.Button("æ¸…ç©ºç»“æœ", elem_classes="btn-secondary")

        # ç¤ºä¾‹
        gr.Examples(
            examples=[
                ["/root/autodl-tmp/ultralytics-main/dataset/images/val/Riped tomato_80.jpeg", 0.25, 0.45],
                ["/root/autodl-tmp/ultralytics-main/dataset/images/val/Riped tomato_4.jpeg", 0.25, 0.45],
            ],
            inputs=[input_img, conf_slider, iou_slider],
            label="å¿«é€Ÿç¤ºä¾‹",
            examples_per_page=2
        )

    # ç»‘å®šäº¤äº’äº‹ä»¶
    submit_btn.click(
        fn=predict_image,
        inputs=[input_img, conf_slider, iou_slider],
        outputs=[original_output, det_output, heatmap_output, feature_visualization_output]
    )
    
    clear_btn.click(
        fn=clear_outputs,
        outputs=[original_output, det_output, heatmap_output, feature_visualization_output]
    )

if __name__ == "__main__":
    demo.launch()    
